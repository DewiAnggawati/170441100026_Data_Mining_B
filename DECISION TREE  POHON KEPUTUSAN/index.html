<!doctype html><html lang="en" class="no-js"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="description" content="A Material Design theme for MkDocs"><link rel="canonical" href="https://DewiAnggawati.github.io/170441100026_Data_Mining_B/DECISION TREE  POHON KEPUTUSAN/"><meta name="author" content="Dewi Anggawati"><meta name="lang:clipboard.copy" content="Copy to clipboard"><meta name="lang:clipboard.copied" content="Copied to clipboard"><meta name="lang:search.language" content="en"><meta name="lang:search.pipeline.stopwords" content="True"><meta name="lang:search.pipeline.trimmer" content="True"><meta name="lang:search.result.none" content="No matching documents"><meta name="lang:search.result.one" content="1 matching document"><meta name="lang:search.result.other" content="# matching documents"><meta name="lang:search.tokenizer" content="[\s\-]+"><link rel="shortcut icon" href="../assets/images/favicon.png"><meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.3.0"><title>Decision Tree - Data Mining</title><link rel="stylesheet" href="../assets/stylesheets/application.4031d38b.css"><link rel="stylesheet" href="../assets/stylesheets/application-palette.224b79ff.css"><meta name="theme-color" content="#3f51b5"><script src="../assets/javascripts/modernizr.74668098.js"></script><link href="https://fonts.gstatic.com" rel="preconnect" crossorigin><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=swap"><style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style><link rel="stylesheet" href="../assets/fonts/material-icons.css"><script>window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })</script><script async src="https://www.google-analytics.com/analytics.js"></script></head><body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo"><svg class="md-svg"><defs><svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg></defs></svg> <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off"> <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off"> <label class="md-overlay" data-md-component="overlay" for="__drawer"></label><a href="#decision-tree-pohon-keputusan" tabindex="1" class="md-skip">Skip to content </a><header class="md-header" data-md-component="header"><nav class="md-header-nav md-grid"><div class="md-flex"><div class="md-flex__cell md-flex__cell--shrink"><a href="https://DewiAnggawati.github.io/170441100026_Data_Mining_B" title="Data Mining" class="md-header-nav__button md-logo"><i class="md-icon"></i></a></div><div class="md-flex__cell md-flex__cell--shrink"><label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label></div><div class="md-flex__cell md-flex__cell--stretch"><div class="md-flex__ellipsis md-header-nav__title" data-md-component="title"><span class="md-header-nav__topic">Data Mining</span><span class="md-header-nav__topic">Decision Tree</span></div></div><div class="md-flex__cell md-flex__cell--shrink"><label class="md-icon md-icon--search md-header-nav__button" for="__search"></label><div class="md-search" data-md-component="search" role="dialog"><label class="md-search__overlay" for="__search"></label><div class="md-search__inner" role="search"><form class="md-search__form" name="search"><input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active"> <label class="md-icon md-search__icon" for="__search"></label> <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">&#xE5CD;</button></form><div class="md-search__output"><div class="md-search__scrollwrap" data-md-scrollfix><div class="md-search-result" data-md-component="result"><div class="md-search-result__meta">Type to start searching</div><ol class="md-search-result__list"></ol></div></div></div></div></div></div><div class="md-flex__cell md-flex__cell--shrink"><div class="md-header-nav__source"><a href="https://github.com/DewiAnggawati/170441100026_Data_Mining_B" title="Go to repository" class="md-source" data-md-source="github"><div class="md-source__icon"><svg viewBox="0 0 24 24" width="24" height="24"><use xlink:href="#__github" width="24" height="24"></use></svg></div><div class="md-source__repository">DewiAnggawati/170441100026_Data_Mining_B</div></a></div></div></div></nav></header><div class="md-container"><nav class="md-tabs" data-md-component="tabs"><div class="md-tabs__inner md-grid"><ul class="md-tabs__list"><li class="md-tabs__item"><a href=".." title="Beranda" class="md-tabs__link md-tabs__link--active">Beranda</a></li></ul></div></nav><main class="md-main"><div class="md-main__inner md-grid" data-md-component="container"><div class="md-sidebar md-sidebar--primary" data-md-component="navigation"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav class="md-nav md-nav--primary" data-md-level="0"><label class="md-nav__title md-nav__title--site" for="__drawer"><a href="https://DewiAnggawati.github.io/170441100026_Data_Mining_B" title="Data Mining" class="md-nav__button md-logo"><i class="md-icon"></i></a>Data Mining</label><div class="md-nav__source"><a href="https://github.com/DewiAnggawati/170441100026_Data_Mining_B" title="Go to repository" class="md-source" data-md-source="github"><div class="md-source__icon"><svg viewBox="0 0 24 24" width="24" height="24"><use xlink:href="#__github" width="24" height="24"></use></svg></div><div class="md-source__repository">DewiAnggawati/170441100026_Data_Mining_B</div></a></div><ul class="md-nav__list" data-md-scrollfix><li class="md-nav__item"><a href=".." title="Beranda" class="md-nav__link">Beranda</a></li><li class="md-nav__item"><a href="../K-Nearest Neighbor (KNN)/" title="K-Nearest Neighbor" class="md-nav__link">K-Nearest Neighbor</a></li><li class="md-nav__item md-nav__item--active"><input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc"><label class="md-nav__link md-nav__link--active" for="__toc">Decision Tree</label><a href="./" title="Decision Tree" class="md-nav__link md-nav__link--active">Decision Tree</a><nav class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc">Table of contents</label><ul class="md-nav__list" data-md-scrollfix><li class="md-nav__item"><a href="#decision-tree-pohon-keputusan" title="DECISION TREE / POHON KEPUTUSAN" class="md-nav__link">DECISION TREE / POHON KEPUTUSAN</a><nav class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a href="#pengertian-pohon-keputusan" title="Pengertian Pohon Keputusan" class="md-nav__link">Pengertian Pohon Keputusan</a></li><li class="md-nav__item"><a href="#manfaat-pohon-keputusan" title="Manfaat Pohon Keputusan" class="md-nav__link">Manfaat Pohon Keputusan</a></li><li class="md-nav__item"><a href="#kelebihan-pohon-keputusan" title="Kelebihan Pohon Keputusan" class="md-nav__link">Kelebihan Pohon Keputusan</a></li><li class="md-nav__item"><a href="#kekurangan-pohon-keputusan" title="Kekurangan Pohon Keputusan" class="md-nav__link">Kekurangan Pohon Keputusan</a></li><li class="md-nav__item"><a href="#study-kasus-decision-tree-univeres" title="Study Kasus (decision tree univeres)" class="md-nav__link">Study Kasus (decision tree univeres)</a></li><li class="md-nav__item"><a href="#referensi" title="Referensi" class="md-nav__link">Referensi</a></li></ul></nav></li></ul></nav></li></ul></nav></div></div></div><div class="md-sidebar md-sidebar--secondary" data-md-component="toc"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc">Table of contents</label><ul class="md-nav__list" data-md-scrollfix><li class="md-nav__item"><a href="#decision-tree-pohon-keputusan" title="DECISION TREE / POHON KEPUTUSAN" class="md-nav__link">DECISION TREE / POHON KEPUTUSAN</a><nav class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a href="#pengertian-pohon-keputusan" title="Pengertian Pohon Keputusan" class="md-nav__link">Pengertian Pohon Keputusan</a></li><li class="md-nav__item"><a href="#manfaat-pohon-keputusan" title="Manfaat Pohon Keputusan" class="md-nav__link">Manfaat Pohon Keputusan</a></li><li class="md-nav__item"><a href="#kelebihan-pohon-keputusan" title="Kelebihan Pohon Keputusan" class="md-nav__link">Kelebihan Pohon Keputusan</a></li><li class="md-nav__item"><a href="#kekurangan-pohon-keputusan" title="Kekurangan Pohon Keputusan" class="md-nav__link">Kekurangan Pohon Keputusan</a></li><li class="md-nav__item"><a href="#study-kasus-decision-tree-univeres" title="Study Kasus (decision tree univeres)" class="md-nav__link">Study Kasus (decision tree univeres)</a></li><li class="md-nav__item"><a href="#referensi" title="Referensi" class="md-nav__link">Referensi</a></li></ul></nav></li></ul></nav></div></div></div><div class="md-content"><article class="md-content__inner md-typeset"><h1>Decision Tree</h1><h3 id="decision-tree-pohon-keputusan"><u>DECISION TREE / POHON KEPUTUSAN</u><a class="headerlink" href="#decision-tree-pohon-keputusan" title="Permanent link">&para;</a></h3>
<h5 id="pengertian-pohon-keputusan">Pengertian Pohon Keputusan<a class="headerlink" href="#pengertian-pohon-keputusan" title="Permanent link">&para;</a></h5>
<p>Salah satu metode data mining yang umum digunakan adalah <a href="http://nugikkool.blogspot.com/2012/08/pohon-keputusan-id3-dan-c45-menggunakan.html">pohon keputusan</a>. Metode pohon keputusan mengubah fakta yang sangat besar menjadi pohon keputusan yang merepresentasikan rule. Pohon keputusan adalah salah satu metode klasifikasi yang paling popular karena mudah untuk diinterpretasi oleh manusia. Konsep dari pohon keputusan adalah mengubah data menjadi pohon keputusan dan aturan-aturan keputusan.</p>
<p>Konsep Pohon Keputusan</p>
<p><img alt="" src="C:\app github pages\mkdocs-material-master\docs\assets\images\konsep.png" /></p>
<p>Data dalam pohon keputusan biasanya dinyatakan dalam bentuk tabel dengan atribut dan record. Atribut menyatakan suatu parameter yang dibuat sebagai kriteria dalam pembentukan tree.</p>
<p>Konsep Data dalam Pohon Keputusan</p>
<p><img alt="" src="C:\app github pages\mkdocs-material-master\docs\assets\images\konsepData.png" /></p>
<p>Proses pada <a href="http://nugikkool.blogspot.com/2012/08/pohon-keputusan-id3-dan-c45-menggunakan.html">pohon keputusan</a> adalah mengubah bentuk data (tabel) menjadi model pohon, mengubah model pohon menjadi rule, dan menyederhanakan rule.</p>
<h5 id="manfaat-pohon-keputusan">Manfaat Pohon Keputusan<a class="headerlink" href="#manfaat-pohon-keputusan" title="Permanent link">&para;</a></h5>
<p>Manfaat utama dari penggunaan pohon keputusan adalah kemampuannya untuk mem-<em>break down</em> proses pengambilan keputusan yang kompleks menjadi lebih simpel sehingga pengambil keputusan akan lebih menginterpretasikan solusi dari permasalahan. Pohon Keputusan juga berguna untuk mengeksplorasi data, menemukan hubungan tersembunyi antara sejumlah calon variabel input dengan sebuah variabel target. Pohon keputusan memadukan antara eksplorasi data dan pemodelan, sehingga  sangat bagus sebagai langkah awal dalam proses pemodelan bahkan ketika dijadikan sebagai model akhir dari beberapa teknik lain. Sering terjadi tawar menawar antara keakuratan model dengan transparansi model. Dalam beberapa aplikasi, akurasi dari sebuah klasifikasi atau prediksi adalah satu-satunya hal yang ditonjolkan, misalnya sebuah perusahaan <em>direct mail</em> membuat sebuah model yang akurat untuk memprediksi anggota mana yang berpotensi untuk merespon permintaan, tanpa memperhatikan bagaimana atau mengapa model tersebut bekerja.</p>
<p>Konsep Dasar Pohon Keputusan</p>
<p><img alt="" src="C:\app github pages\mkdocs-material-master\docs\assets\images\konsepDasar.png" /></p>
<p>Bagian awal dari pohon keputusan ini adalah titik akar (root), sedangkan setiap cabang dari pohon keputusan merupakan pembagian berdasarkan hasil uji, dan titik akhir (leaf) merupakan pembagian kelas yang dihasilkan.</p>
<p>Pohon keputusan mempunyai 3 tipe simpul yaitu:</p>
<ol>
<li>
<p>Simpul akar, dimana tidak memiliki cabang yang masuk dan memiliki cabang lebih dari satu, terkadang tidak memiliki cabang sama sekali. Simpul ini biasanya berupa atribut yang paling memiliki pengaruh terbesar pada suatu kelas tertentu.</p>
</li>
<li>
<p>Simpul internal, dimana hanya memiliki 1 cabang yang masuk, dan memiliki lebih dari 1 cabang yang keluar.</p>
</li>
<li>
<p>Simpul daun, atau simpul akhir dimana hanya memiliki 1 cabang yang masuk, dan tidak memiliki cabang sama sekali dan menandai bahwa simpul tersebut merupakan label kelas.</p>
</li>
</ol>
<p>Tahap awal dilakukan pengujian simpul akar, jika pada pengujian simpul akar menghasilkan sesuatu maka proses pengujian juga dilakukan pada setiap cabang berdasarkan hasil dari pengujian. Hal ini berlaku juga untuk simpul internal dimana suatu kondisi pengujian baru akan diterapkan pada simpul daun. Pada umumnya proses dari sistem pohon keputusan adalah mengadopsi strategi pencarian top-down untuk solusi ruang pencariannya. Pada proses mengklasifikasikan sampel yang tidak diketahui, nilai atribut akan diuji pada pohon keputusan dengan cara melacak jalur dari titik akar sampai titik akhir, kemudian akan diprediksikan kelas yang ditempati sampel baru tersebut.</p>
<h5 id="kelebihan-pohon-keputusan">Kelebihan Pohon Keputusan<a class="headerlink" href="#kelebihan-pohon-keputusan" title="Permanent link">&para;</a></h5>
<p>Kelebihan dari metode pohon keputusan adalah:</p>
<ul>
<li>Daerah pengambilan keputusan yang sebelumnya kompleks dan sangat global, dapat diubah menjadi lebih simpel dan spesifik.</li>
<li>Eliminasi perhitungan-perhitungan yang tidak diperlukan, karena ketika menggunakan metode pohon keputusan maka sample diuji hanya berdasarkan kriteria atau kelas tertentu.</li>
<li>Fleksibel untuk memilih fitur dari internal node yang berbeda, fitur yang terpilih akan membedakan suatu kriteria dibandingkan kriteria yang lain dalam node yang sama. Kefleksibelan metode pohon keputusan ini meningkatkan kualitas keputusan yang dihasilkan jika dibandingkan ketika menggunakan metode penghitungan satu tahap yang lebih konvensional.</li>
<li>Dalam analisis multivariat, dengan kriteria dan kelas yang jumlahnya sangat banyak, seorang penguji biasanya perlu untuk mengestimasikan baik itu distribusi dimensi tinggi ataupun parameter tertentu dari distribusi kelas tersebut. Metode pohon keputusan dapat menghindari munculnya permasalahan ini dengan menggunakan criteria yang jumlahnya lebih sedikit pada setiap node internal tanpa banyak mengurangi kualitas keputusan yang dihasilkan.</li>
</ul>
<h5 id="kekurangan-pohon-keputusan">Kekurangan Pohon Keputusan<a class="headerlink" href="#kekurangan-pohon-keputusan" title="Permanent link">&para;</a></h5>
<ul>
<li>Terjadi overlap terutama ketika kelas-kelas dan criteria yang digunakan jumlahnya sangat banyak. Hal tersebut juga dapat menyebabkan meningkatnya waktu pengambilan keputusan dan jumlah memori yang diperlukan.</li>
<li>Pengakumulasian jumlah eror dari setiap tingkat dalam sebuah pohon keputusan yang besar.</li>
<li>Kesulitan dalam mendesain pohon keputusan yang optimal.</li>
<li>Hasil kualitas keputusan yang didapatkan dari metode pohon keputusan sangat tergantung pada bagaimana pohon tersebut didesain.</li>
</ul>
<p><strong>Model Pohon Keputusan</strong></p>
<p><img alt="" src="C:\app github pages\mkdocs-material-master\docs\assets\images\modelPohonKeputusan.png" /></p>
<p>Disini setiap percabangan menyatakan kondisi yang harus dipenuhi dan tiap ujung pohon menyatakan kelas data.</p>
<p>Contoh di Gambar diatas adalah identifikasi pembeli komputer,dari pohon keputusan tersebut diketahui bahwa salah satu kelompok yang potensial membeli komputer adalah orang yang berusia di bawah 30 tahun dan juga pelajar. Setelah sebuah pohon keputusan dibangun maka dapat digunakan untuk mengklasifikasikan <em>record</em> yang belum ada kelasnya. Dimulai dari <em>node root</em>, menggunakan tes terhadap atribut dari <em>record</em> yang belum ada kelasnya tersebut lalu mengikuti cabang yang sesuai dengan hasil dari tes tersebut, yang akan membawa kepada <em>internal node</em> (<em>node</em> yang memiliki satu cabang masuk dan dua atau lebih cabang yang keluar), dengan cara harus melakukan tes lagi terhadap atribut atau <em>node</em> daun. <em>Record</em> yang kelasnya tidak diketahui kemudian diberikan kelas yang sesuai dengan kelas yang ada pada <em>node</em> daun. Pada pohon keputusan setiap simpul daun menandai label kelas. Proses dalam pohon keputusan yaitu mengubah bentuk data (tabel) menjadi model pohon (<em>tree</em>) kemudian mengubah model pohon tersebut menjadi aturan (<em>rule</em>).</p>
<p><strong>ALGORITMA C4.5</strong></p>
<p>Pohon dibangun dengan cara membagi data secara rekursif hingga tiap bagian terdiri dari data yang berasal dari kelas yang sama. Bentuk pemecahan (<em>split)</em> yang digunakan untuk membagi data tergantung dari jenis atribut yang digunakan dalam <em>split</em>. Algoritma C4.5 dapat menangani data numerik (kontinyu) dan diskret. <em>Split</em> untuk atribut numerik yaitu mengurutkan contoh berdasarkan atribut kontiyu A, kemudian membentuk minimum permulaan <em>(threshold</em>) M dari contoh-contoh yang ada dari kelas mayoritas pada setiap partisi yang bersebelahan, lalu menggabungkan partisi-partisi yang bersebelahan tersebut dengan kelas mayoritas yang sama. <em>Split</em> untuk atribut diskret <em>A</em> mempunyai bentuk <em>value (A)</em> ε <em>X</em> dimana <em>X</em> ⊂ <em>domain(A)</em>.</p>
<p>Jika suatu set data mempunyai beberapa pengamatan dengan <em>missing value</em> yaitu <em>record</em> dengan beberapa nilai variabel tidak ada, Jika jumlah pengamatan terbatas maka atribut dengan <em>missing value</em> dapat diganti dengan nilai rata-rata dari variabel yang bersangkutan.[Santosa,2007]</p>
<p>Untuk melakukan pemisahan obyek (<em>split)</em> dilakukan tes terhadap atribut dengan mengukur tingkat ketidakmurnian pada sebuah simpul (<em>node)</em>. Pada algoritma C.45 menggunakan rasio perolehan (<em>gain ratio</em>). Sebelum menghitung rasio perolehan, perlu menghitung dulu nilai informasi dalam satuan bits dari suatu kumpulan objek. Cara menghitungnya dilakukan dengan menggunakan konsep entropi.</p>
<p><img alt="" src="C:\app github pages\mkdocs-material-master\docs\assets\images\algoritm1.png" /></p>
<p><em>S</em> adalah ruang (data) sampel yang digunakan untuk pelatihan, <em>p+</em> adalah jumlah yang bersolusi positif atau mendukung pada data sampel untuk kriteria tertentu dan <em>p-</em> adalah jumlah yang bersolusi negatif atau tidak mendukung pada data sampel untuk kriteria tertentu. ntropi(<em>S</em>) sama dengan 0, jika semua contoh pada S berada dalam kelas yang sama. Entropi(S) sama dengan 1, jika jumlah contoh positif dan negative dalam S adalah sama. Entropi(S) lebih dari 0 tetapi kurang dari 1, jika jumlah contoh positif dan negative dalam S tidak sama [Mitchell,1997].Entropi split yang membagi <em>S</em> dengan <em>n</em> record menjadi himpunan-himpunan <em>S1</em> dengan <em>n1</em> baris dan <em>S2</em> dengan <em>n2</em> baris adalah :</p>
<p><img alt="" src="C:\app github pages\mkdocs-material-master\docs\assets\images\algoritm2.png" /></p>
<p>Kemudian menghitung perolehan informasi dari output data atau variabel dependent <em>y</em> yang dikelompokkan berdasarkan atribut A, dinotasikan dengan <em>gain</em> (<em>y</em>,A). Perolehan informasi*, gain* (<em>y</em>,A), dari atribut A relative terhadap output data <em>y</em> adalah:</p>
<p><img alt="" src="C:\app github pages\mkdocs-material-master\docs\assets\images\algoritm4.png" /></p>
<p>nilai (A) adalah semua nilai yang mungkin dari atribut A, dan <em>y*c adalah subset dari y dimana A mempunyai nilai c. Term pertama dalam persamaan diatas adalah *entropy</em> total <em>y</em> dan term kedua adalah entropy sesudah dilakukan pemisahan data berdasarkan atribut A.</p>
<p>Untuk menghitung rasio perolehan perlu diketahui suatu term baru yang disebut pemisahan informasi <em>(SplitInfo</em>). Pemisahan informasi dihitung dengan cara :</p>
<p><img alt="" src="C:\app github pages\mkdocs-material-master\docs\assets\images\algoritm4.png" /></p>
<p>bahwa <em>S1</em> sampai <em>Sc</em> adalah <em>c</em> subset yang dihasilkan dari pemecahan <em>S</em> dengan menggunakan atribut A yang mempunyai sebanyak <em>c</em> nilai. Selanjutnya rasio perolehan (gain ratio) dihitung dengan cara :</p>
<p><img alt="" src="C:\app github pages\mkdocs-material-master\docs\assets\images\algoritm5.png" /></p>
<h4 id="study-kasus-decision-tree-univeres">Study Kasus (decision tree univeres)<a class="headerlink" href="#study-kasus-decision-tree-univeres" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="c1"># In[1]:</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span> 
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span> 
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_graphviz</span>
<span class="kn">from</span> <span class="nn">sklearn.externals.six</span> <span class="kn">import</span> <span class="n">StringIO</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>  
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">import</span> <span class="nn">pydotplus</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c1"># In[4]:</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;UniversalBank.csv&#39;</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1"># In[5]:</span>

<span class="n">data</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>

<span class="c1"># In[6]:</span>

<span class="n">zero_not_accepted</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ID&#39;</span><span class="p">,</span><span class="s1">&#39;Age&#39;</span><span class="p">,</span><span class="s1">&#39;Experience&#39;</span><span class="p">,</span><span class="s1">&#39;Income&#39;</span><span class="p">,</span><span class="s1">&#39;ZIP Code&#39;</span><span class="p">,</span><span class="s1">&#39;Family&#39;</span><span class="p">,</span><span class="s1">&#39;CCAvg&#39;</span><span class="p">,</span><span class="s1">&#39;Education&#39;</span><span class="p">,</span><span class="s1">&#39;Mortgage&#39;</span><span class="p">,</span>
                     <span class="s1">&#39;Personal Loan&#39;</span><span class="p">,</span><span class="s1">&#39;Personal Loan&#39;</span><span class="p">,</span><span class="s1">&#39;Securities Account&#39;</span><span class="p">,</span><span class="s1">&#39;CD Account&#39;</span><span class="p">]</span>
<span class="c1"># for col in zero_not_accepted:</span>
<span class="c1">#     for i in data[col]:</span>
<span class="c1">#         if i==0:</span>
<span class="c1">#             colSum = sum(data[col])</span>
<span class="c1">#             meanCol=colSum/len(data[col])</span>
<span class="c1">#             data[col]=meanCol</span>

<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">zero_not_accepted</span><span class="p">:</span>
    <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">NaN</span><span class="p">)</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">skipna</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
    <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">NaN</span><span class="p">,</span><span class="n">mean</span><span class="p">)</span>

<span class="c1"># In[8]:</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s1">&#39;ID&#39;</span><span class="p">,</span><span class="s1">&#39;Age&#39;</span><span class="p">,</span><span class="s1">&#39;Experience&#39;</span><span class="p">,</span><span class="s1">&#39;Income&#39;</span><span class="p">,</span><span class="s1">&#39;ZIP Code&#39;</span><span class="p">,</span><span class="s1">&#39;Family&#39;</span><span class="p">,</span><span class="s1">&#39;CCAvg&#39;</span><span class="p">,</span><span class="s1">&#39;Education&#39;</span><span class="p">,</span><span class="s1">&#39;Mortgage&#39;</span><span class="p">,</span><span class="s1">&#39;Personal Loan&#39;</span><span class="p">,</span>
          <span class="s1">&#39;Personal Loan&#39;</span><span class="p">,</span><span class="s1">&#39;Securities Account&#39;</span><span class="p">,</span><span class="s1">&#39;CD Account&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Online&#39;</span><span class="p">]</span>

<span class="c1">#memecah data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># In[13]:</span>

<span class="c1"># Buat objek classifer Pohon Keputusan</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;entropy&quot;</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Melatih Pohon Pengambilan Keputusan</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1">#Prediksikan respons untuk dataset uji</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Model Accuracy, seberapa sering penggolongnya benar?</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1"># In[14]:</span>

<span class="n">feature_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ID&#39;</span><span class="p">,</span><span class="s1">&#39;Age&#39;</span><span class="p">,</span><span class="s1">&#39;Experience&#39;</span><span class="p">,</span><span class="s1">&#39;Income&#39;</span><span class="p">,</span><span class="s1">&#39;ZIP Code&#39;</span><span class="p">,</span><span class="s1">&#39;Family&#39;</span><span class="p">,</span><span class="s1">&#39;CCAvg&#39;</span><span class="p">,</span><span class="s1">&#39;Education&#39;</span><span class="p">,</span><span class="s1">&#39;Mortgage&#39;</span><span class="p">,</span><span class="s1">&#39;Personal Loan&#39;</span><span class="p">,</span>
                <span class="s1">&#39;Personal Loan&#39;</span><span class="p">,</span><span class="s1">&#39;Securities Account&#39;</span><span class="p">,</span><span class="s1">&#39;CD Account&#39;</span><span class="p">]</span>
<span class="n">dot_data</span> <span class="o">=</span> <span class="n">StringIO</span><span class="p">()</span>
<span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="n">dot_data</span><span class="p">,</span>  
                <span class="n">filled</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                <span class="n">special_characters</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">feature_names</span> <span class="o">=</span> <span class="n">feature_cols</span><span class="p">,</span><span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;0&#39;</span><span class="p">,</span><span class="s1">&#39;1&#39;</span><span class="p">])</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">pydotplus</span><span class="o">.</span><span class="n">graph_from_dot_data</span><span class="p">(</span><span class="n">dot_data</span><span class="o">.</span><span class="n">getvalue</span><span class="p">())</span>  
<span class="n">graph</span><span class="o">.</span><span class="n">write_png</span><span class="p">(</span><span class="s1">&#39;bank.png&#39;</span><span class="p">)</span>
<span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">create_png</span><span class="p">())</span>

<span class="c1"># In[ ]:</span>
</pre></div>

<h4 id="referensi">Referensi<a class="headerlink" href="#referensi" title="Permanent link">&para;</a></h4>
<p><a href="https://fairuzelsaid.wordpress.com/2009/11/24/data-mining-konsep-pohon-keputusan/">https://fairuzelsaid.wordpress.com/2009/11/24/data-mining-konsep-pohon-keputusan/</a></p>
<p><a href="http://nugikkool.blogspot.com/2012/08/pohon-keputusan-id3-dan-c45-menggunakan.html">http://nugikkool.blogspot.com/2012/08/pohon-keputusan-id3-dan-c45-menggunakan.html</a></p></article></div></div></main><footer class="md-footer"><div class="md-footer-nav"><nav class="md-footer-nav__inner md-grid"><a href="../K-Nearest Neighbor (KNN)/" title="K-Nearest Neighbor" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev"><div class="md-flex__cell md-flex__cell--shrink"><i class="md-icon md-icon--arrow-back md-footer-nav__button"></i></div><div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span class="md-flex__ellipsis"><span class="md-footer-nav__direction">Previous</span>K-Nearest Neighbor</span></div></a></nav></div><div class="md-footer-meta md-typeset"><div class="md-footer-meta__inner md-grid"><div class="md-footer-copyright"><div class="md-footer-copyright__highlight">Copyright &copy; 2016 - 2019 Martin Donath</div>powered by <a href="https://www.mkdocs.org">MkDocs</a> and <a href="https://squidfunk.github.io/mkdocs-material/">Material for MkDocs</a></div><div class="md-footer-social"><link rel="stylesheet" href="../assets/fonts/font-awesome.css"> <a href="http://struct.cc" class="md-footer-social__link fa fa-globe"></a>  <a href="https://github.com/squidfunk" class="md-footer-social__link fa fa-github-alt"></a>  <a href="https://twitter.com/squidfunk" class="md-footer-social__link fa fa-twitter"></a>  <a href="https://linkedin.com/in/squidfunk" class="md-footer-social__link fa fa-linkedin"></a> </div></div></div></footer></div><script src="../assets/javascripts/application.d5a09f94.js"></script><script>app.initialize({version:"1.0.4",url:{base:".."}})</script></body></html>